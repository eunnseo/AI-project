{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbdbd453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index    0\n",
      "QaA      0\n",
      "QaE      0\n",
      "QbA      0\n",
      "QbE      0\n",
      "        ..\n",
      "wr_09    0\n",
      "wr_10    0\n",
      "wr_11    0\n",
      "wr_12    0\n",
      "wr_13    0\n",
      "Length: 78, dtype: int64\n",
      "education 0 건수는 432, 퍼센트는 1.19 %\n",
      "engnat 0 건수는 63, 퍼센트는 0.17 %\n",
      "hand 0 건수는 135, 퍼센트는 0.37 %\n",
      "urban 0 건수는 258, 퍼센트는 0.71 %\n",
      "['QaE', 'QbE', 'QcE', 'QdE', 'QeE', 'QfE', 'QgE', 'QhE', 'QiE', 'QjE', 'QkE', 'QlE', 'QmE', 'QnE', 'QoE', 'QpE', 'QqE', 'QrE', 'QsE', 'QtE']\n",
      "QaE 0 건수는 0, 퍼센트는 0.00 %\n",
      "QbE 0 건수는 0, 퍼센트는 0.00 %\n",
      "QcE 0 건수는 0, 퍼센트는 0.00 %\n",
      "QdE 0 건수는 0, 퍼센트는 0.00 %\n",
      "QeE 0 건수는 0, 퍼센트는 0.00 %\n",
      "QfE 0 건수는 0, 퍼센트는 0.00 %\n",
      "QgE 0 건수는 0, 퍼센트는 0.00 %\n",
      "QhE 0 건수는 1, 퍼센트는 0.00 %\n",
      "QiE 0 건수는 1, 퍼센트는 0.00 %\n",
      "QjE 0 건수는 1, 퍼센트는 0.00 %\n",
      "QkE 0 건수는 2, 퍼센트는 0.01 %\n",
      "QlE 0 건수는 0, 퍼센트는 0.00 %\n",
      "QmE 0 건수는 0, 퍼센트는 0.00 %\n",
      "QnE 0 건수는 0, 퍼센트는 0.00 %\n",
      "QoE 0 건수는 0, 퍼센트는 0.00 %\n",
      "QpE 0 건수는 1, 퍼센트는 0.00 %\n",
      "QqE 0 건수는 1, 퍼센트는 0.00 %\n",
      "QrE 0 건수는 0, 퍼센트는 0.00 %\n",
      "QsE 0 건수는 0, 퍼센트는 0.00 %\n",
      "QtE 0 건수는 0, 퍼센트는 0.00 %\n",
      "['tp01', 'tp02', 'tp03', 'tp04', 'tp05', 'tp06', 'tp07', 'tp08', 'tp09', 'tp10']\n",
      "tp01 0 건수는 3822, 퍼센트는 10.49 %\n",
      "tp02 0 건수는 4356, 퍼센트는 11.96 %\n",
      "tp03 0 건수는 9348, 퍼센트는 25.66 %\n",
      "tp04 0 건수는 4414, 퍼센트는 12.12 %\n",
      "tp05 0 건수는 12682, 퍼센트는 34.82 %\n",
      "tp06 0 건수는 7148, 퍼센트는 19.62 %\n",
      "tp07 0 건수는 7858, 퍼센트는 21.57 %\n",
      "tp08 0 건수는 2547, 퍼센트는 6.99 %\n",
      "tp09 0 건수는 7027, 퍼센트는 19.29 %\n",
      "tp10 0 건수는 1158, 퍼센트는 3.18 %\n",
      "Index(['QaA', 'QaE', 'QbA', 'QbE', 'QcA', 'QcE', 'QdA', 'QdE', 'QeA', 'QeE',\n",
      "       ...\n",
      "       'religion_Christian_Protestant', 'religion_Hindu', 'religion_Jewish',\n",
      "       'religion_Muslim', 'religion_Other', 'religion_Sikh', 'urban_1.0',\n",
      "       'urban_2.0', 'urban_2.1795744680851064', 'urban_3.0'],\n",
      "      dtype='object', length=112)\n",
      "오차행렬\n",
      "[[3666  292]\n",
      " [ 423  544]]\n",
      "정확도: 0.8548, 정밀도: 0.6507, 재현율: 0.5626, F1: 0.6034, AUC:0.9230\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "import imblearn\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from xgboost import plot_importance\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "data_p = pd.read_csv(\"train.csv\")\n",
    "\n",
    "#결손값 처리\n",
    "data_p.isna().head(3)\n",
    "print(data_p.isna().sum())\n",
    "\n",
    "\n",
    "####0값을 검사할 피처명 리스트 객체 설정\n",
    "\n",
    "\n",
    "#무응답 해당 피처 : education, engnat, hand, urban\n",
    "zero_features = ['education', 'engnat', 'hand', 'urban']\n",
    "    \n",
    "#전체 데이터 건수\n",
    "total_count = data_p['education'].count()\n",
    "\n",
    "#피처별로 반복 하면서 데이터 값이 0인 데이터 건수 추출하고, 퍼센트 계산\n",
    "for feature in zero_features:\n",
    "    zero_count = data_p[data_p[feature] == 0][feature].count()\n",
    "    print('{0} 0 건수는 {1}, 퍼센트는 {2:.2f} %'.format(feature,  zero_count, 100* zero_count/total_count))\n",
    "    \n",
    "    \n",
    "Q_E = []\n",
    "#Q_E 시간\n",
    "for i in range(97, 117):\n",
    "    a = 'Q' + chr(i) + 'E'\n",
    "    Q_E.append(a)\n",
    "    \n",
    "print(Q_E)\n",
    "    \n",
    "for feature in Q_E:\n",
    "    zero_count = data_p[data_p[feature] == 0][feature].count()\n",
    "    print('{0} 0 건수는 {1}, 퍼센트는 {2:.2f} %'.format(feature,  zero_count, 100* zero_count/total_count))\n",
    "\n",
    "    \n",
    "    \n",
    "#tp\n",
    "TP = []\n",
    "for i in range(1,10):\n",
    "        a = 'tp0' + str(i)\n",
    "        TP.append(a)\n",
    "TP.append('tp10')\n",
    "print(TP)\n",
    "\n",
    "for feature in TP:\n",
    "    zero_count = data_p[data_p[feature] == 0][feature].count()\n",
    "    print('{0} 0 건수는 {1}, 퍼센트는 {2:.2f} %'.format(feature,  zero_count, 100* zero_count/total_count)) \n",
    "    \n",
    "    \n",
    "    \n",
    "#0값을 평균값으로 대체\n",
    "data_p[zero_features]=data_p[zero_features].replace(0, data_p[zero_features].mean())\n",
    "\n",
    "\n",
    "\n",
    "#시간에 대해 이상치 데이터 인덱스 확인 및 제거\n",
    "\n",
    "def get_outlier(df=None, column=None, weight=1.5):\n",
    "    fraud = df[df['voted']==1][column]\n",
    "    quantile_25 = np.percentile(fraud.values, 25)\n",
    "    quantile_75 = np.percentile(fraud.values, 75)\n",
    "    \n",
    "    iqr = quantile_75 - quantile_25\n",
    "    iqr_weight = iqr * weight\n",
    "    lowest_val = quantile_25 - iqr_weight\n",
    "    highest_val = quantile_75 + iqr_weight    \n",
    "    outlier_index = fraud[(fraud < lowest_val) | (fraud > highest_val)].index    \n",
    "    return outlier_index\n",
    "\n",
    "\n",
    "for feature in Q_E:\n",
    "    outlier_index = get_outlier(df=data_p, column=feature, weight=1.5)\n",
    "    #print('이상치 데이터 인덱스 :', outlier_index)\n",
    "    data_p.drop(outlier_index, axis=0, inplace=True)\n",
    "\n",
    "    \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#원핫인코딩 진행\n",
    "def dummy_data(data, columns) :\n",
    "    for column in columns:\n",
    "        data = pd.concat([data, pd.get_dummies(data[column], prefix = column)], axis=1)\n",
    "        data = data.drop(column, axis=1)\n",
    "    return data\n",
    "\n",
    "dummy_columns = ['age_group', 'engnat', 'gender','hand', 'married', 'race', 'religion', 'urban']\n",
    "data_k = dummy_data(data_p, dummy_columns)\n",
    "\n",
    "data_k = data_k.drop('index', axis=1)\n",
    "\n",
    "print(data_k.columns)\n",
    "'''\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data_k)\n",
    "data_scaled = scaler.transform(data_k)\n",
    "data_scaled_df = pd.DataFrame(data=data_scaled)\n",
    "'''\n",
    "\n",
    "\n",
    "y = data_k['voted']\n",
    "X_features=data_k.drop('voted', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size =0.2, random_state=156)\n",
    "\n",
    "xgb_wrapper = XGBClassifier(n_estibators=400, learning_rate=0.1, max_depth=3)\n",
    "xgb_wrapper.fit(X_train, y_train)\n",
    "w_preds = xgb_wrapper.predict(X_test)\n",
    "w_pred_proba = xgb_wrapper.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))\n",
    "    \n",
    "get_clf_eval(y_test, w_preds, w_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57e6377",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
